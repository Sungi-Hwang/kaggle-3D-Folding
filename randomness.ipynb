{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6fec05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T05:37:06.499434Z",
     "iopub.status.busy": "2025-05-13T05:37:06.499163Z",
     "iopub.status.idle": "2025-05-13T05:37:06.503927Z",
     "shell.execute_reply": "2025-05-13T05:37:06.503191Z"
    },
    "papermill": {
     "duration": 0.011608,
     "end_time": "2025-05-13T05:37:06.505269",
     "exception": false,
     "start_time": "2025-05-13T05:37:06.493661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_TYPE='protenix'\n",
    "VALIDATION=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a9fa6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T05:37:06.512970Z",
     "iopub.status.busy": "2025-05-13T05:37:06.512716Z",
     "iopub.status.idle": "2025-05-13T05:37:09.453406Z",
     "shell.execute_reply": "2025-05-13T05:37:09.452528Z"
    },
    "papermill": {
     "duration": 2.946011,
     "end_time": "2025-05-13T05:37:09.455001",
     "exception": false,
     "start_time": "2025-05-13T05:37:06.508990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: biopython\r\n",
      "Version: 1.85\r\n",
      "Summary: Freely available tools for computational molecular biology.\r\n",
      "Home-page: https://biopython.org/\r\n",
      "Author: The Biopython Contributors\r\n",
      "Author-email: biopython@biopython.org\r\n",
      "License: \r\n",
      "Location: /usr/local/lib/python3.10/dist-packages\r\n",
      "Requires: numpy\r\n",
      "Required-by: protenix\r\n"
     ]
    }
   ],
   "source": [
    "!pip show biopython\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d09eed",
   "metadata": {
    "papermill": {
     "duration": 0.003229,
     "end_time": "2025-05-13T05:37:09.462115",
     "exception": false,
     "start_time": "2025-05-13T05:37:09.458886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install requirements "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53845a4",
   "metadata": {
    "papermill": {
     "duration": 0.003045,
     "end_time": "2025-05-13T05:37:09.468432",
     "exception": false,
     "start_time": "2025-05-13T05:37:09.465387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "RNA 3D 예측 결과와 실제 구조를 비교하고, 이를 평가하는 파이프 라인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e45477a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T05:37:09.476163Z",
     "iopub.status.busy": "2025-05-13T05:37:09.475911Z",
     "iopub.status.idle": "2025-05-13T05:37:23.645960Z",
     "shell.execute_reply": "2025-05-13T05:37:23.645004Z"
    },
    "papermill": {
     "duration": 14.175754,
     "end_time": "2025-05-13T05:37:23.647618",
     "exception": false,
     "start_time": "2025-05-13T05:37:09.471864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protenix in /usr/local/lib/python3.10/dist-packages (0.4.6)\r\n",
      "Requirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (1.85)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->biopython) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->biopython) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->biopython) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->biopython) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->biopython) (2024.2.0)\r\n",
      "Requirement already satisfied: ml-collections in /usr/local/lib/python3.10/dist-packages (1.1.0)\r\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from ml-collections) (1.4.0)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from ml-collections) (6.0.2)\r\n",
      "Requirement already satisfied: biotite==1.0.1 in /usr/local/lib/python3.10/dist-packages (1.0.1)\r\n",
      "Requirement already satisfied: biotraj<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from biotite==1.0.1) (1.2.2)\r\n",
      "Requirement already satisfied: msgpack>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from biotite==1.0.1) (1.1.0)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from biotite==1.0.1) (3.4.2)\r\n",
      "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.10/dist-packages (from biotite==1.0.1) (1.26.4)\r\n",
      "Requirement already satisfied: requests>=2.12 in /usr/local/lib/python3.10/dist-packages (from biotite==1.0.1) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.10/dist-packages (from biotraj<2.0,>=1.0->biotite==1.0.1) (1.13.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.25->biotite==1.0.1) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.25->biotite==1.0.1) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.25->biotite==1.0.1) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.25->biotite==1.0.1) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.25->biotite==1.0.1) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.25->biotite==1.0.1) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12->biotite==1.0.1) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12->biotite==1.0.1) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12->biotite==1.0.1) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12->biotite==1.0.1) (2025.1.31)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.25->biotite==1.0.1) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.25->biotite==1.0.1) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.25->biotite==1.0.1) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.25->biotite==1.0.1) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.25->biotite==1.0.1) (2024.2.0)\r\n",
      "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2025.3.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.26.4)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (11.0.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rdkit) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rdkit) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->rdkit) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->rdkit) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->rdkit) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "if MODEL_TYPE=='protenix' and VALIDATION:\n",
    "    !pip install --no-deps protenix\n",
    "    !pip install biopython\n",
    "    !pip install ml-collections\n",
    "    !pip install biotite==1.0.1\n",
    "    !pip install rdkit\n",
    "!export PROTENIX_DATA_ROOT_DIR=/kaggle/input/protenix-checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4389989a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T05:37:23.656713Z",
     "iopub.status.busy": "2025-05-13T05:37:23.656481Z",
     "iopub.status.idle": "2025-05-13T05:37:24.011306Z",
     "shell.execute_reply": "2025-05-13T05:37:24.010195Z"
    },
    "papermill": {
     "duration": 0.361036,
     "end_time": "2025-05-13T05:37:24.012956",
     "exception": false,
     "start_time": "2025-05-13T05:37:23.651920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "components.v20240608.cif\t\tmodel_v0.2.0.pt\r\n",
      "components.v20240608.cif.rdkit_mol.pkl\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir /af3-dev \n",
    "! ln -s /kaggle/input/protenix-checkpoints /af3-dev/release_data\n",
    "! ls /af3-dev/release_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e31df9",
   "metadata": {
    "papermill": {
     "duration": 0.003638,
     "end_time": "2025-05-13T05:37:24.020757",
     "exception": false,
     "start_time": "2025-05-13T05:37:24.017119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "529fda22",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-13T05:37:24.029286Z",
     "iopub.status.busy": "2025-05-13T05:37:24.028998Z",
     "iopub.status.idle": "2025-05-13T05:37:28.646226Z",
     "shell.execute_reply": "2025-05-13T05:37:28.645181Z"
    },
    "papermill": {
     "duration": 4.623283,
     "end_time": "2025-05-13T05:37:28.647726",
     "exception": false,
     "start_time": "2025-05-13T05:37:24.024443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT OK !!!!\n"
     ]
    }
   ],
   "source": [
    "import Bio\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "from Bio.PDB import Atom, Model, Chain, Residue, Structure, PDBParser\n",
    "from Bio import SeqIO\n",
    "import os, sys\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "time0=time.time()\n",
    "\n",
    "print('IMPORT OK !!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c7b4ac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T05:37:28.658149Z",
     "iopub.status.busy": "2025-05-13T05:37:28.657734Z",
     "iopub.status.idle": "2025-05-13T05:37:28.784157Z",
     "shell.execute_reply": "2025-05-13T05:37:28.783124Z"
    },
    "papermill": {
     "duration": 0.133013,
     "end_time": "2025-05-13T05:37:28.785563",
     "exception": false,
     "start_time": "2025-05-13T05:37:28.652550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHON /usr/bin/python3\n",
      "HELPER OK!!!\n"
     ]
    }
   ],
   "source": [
    "PYTHON = sys.executable\n",
    "print('PYTHON',PYTHON)\n",
    "\n",
    "RHONET_DIR=\\\n",
    "'/kaggle/input/data-for-demo-for-rhofold-plus-with-kaggle-msa/RhoFold-main'\n",
    "#'<your downloaded rhofold repo>/RhoFold-main'\n",
    "\n",
    "USALIGN = \\\n",
    "'/kaggle/working//USalign'\n",
    "#'<your us align path>/USalign'\n",
    "\n",
    "os.system('cp /kaggle/input/usalign/USalign /kaggle/working/')\n",
    "os.system('sudo chmod u+x /kaggle/working//USalign')\n",
    "sys.path.append(RHONET_DIR)\n",
    "\n",
    "\n",
    "DATA_KAGGLE_DIR = '/kaggle/input/stanford-rna-3d-folding'\n",
    "\n",
    "\n",
    "# helper ----\n",
    "# 딕셔너리 <-> 키 매핑\n",
    "class dotdict(dict):\n",
    "\t__setattr__ = dict.__setitem__\n",
    "\t__delattr__ = dict.__delitem__\n",
    "\n",
    "\tdef __getattr__(self, name):\n",
    "\t\ttry:\n",
    "\t\t\treturn self[name]\n",
    "\t\texcept KeyError:\n",
    "\t\t\traise AttributeError(name)\n",
    "\n",
    "# visualisation helper ----\n",
    "def set_aspect_equal(ax):\n",
    "\tx_limits = ax.get_xlim()\n",
    "\ty_limits = ax.get_ylim()\n",
    "\tz_limits = ax.get_zlim()\n",
    "\n",
    "\t# Compute the mean of each axis\n",
    "\tx_middle = np.mean(x_limits)\n",
    "\ty_middle = np.mean(y_limits)\n",
    "\tz_middle = np.mean(z_limits)\n",
    "\n",
    "\t# Compute the max range across all axes\n",
    "\tmax_range = max(x_limits[1] - x_limits[0],\n",
    "\t\t\t\t\ty_limits[1] - y_limits[0],\n",
    "\t\t\t\t\tz_limits[1] - z_limits[0]) / 2.0\n",
    "\n",
    "\t# Set the new limits to ensure equal scaling\n",
    "\tax.set_xlim(x_middle - max_range, x_middle + max_range)\n",
    "\tax.set_ylim(y_middle - max_range, y_middle + max_range)\n",
    "\tax.set_zlim(z_middle - max_range, z_middle + max_range)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# xyz df helper --------------------\n",
    "def get_truth_df(target_id):\n",
    "    truth_df = LABEL_DF[LABEL_DF['target_id'] == target_id]\n",
    "    truth_df = truth_df.reset_index(drop=True)\n",
    "    return truth_df\n",
    "\n",
    "def parse_output_to_df(output, seq, target_id):\n",
    "    df = []\n",
    "    chain_data = []\n",
    "    for i, res in enumerate(seq):\n",
    "        d=dict(ID = target_id,\n",
    "                    resname=res,\n",
    "                    resid=i+1)\n",
    "        for n in range(len(output)):\n",
    "            d={**d, f'x_{n+1}': round(output[n,i,0].item(),3),\n",
    "                     f'y_{n+1}': round(output[n,i,1].item(),3),\n",
    "                     f'z_{n+1}': round(output[n,i,2].item(),3)}\n",
    "        chain_data.append(d)\n",
    "\n",
    "    if len(chain_data)!=0:\n",
    "        chain_df = pd.DataFrame(chain_data)\n",
    "        df.append(chain_df)\n",
    "        ##print(chain_df)\n",
    "    return df\n",
    "\n",
    "def parse_pdb_to_df(pdb_file, target_id):\n",
    "    parser = PDBParser()\n",
    "    structure = parser.get_structure('', pdb_file)\n",
    "\n",
    "    df = []\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            print(chain)\n",
    "            chain_data = []\n",
    "            for residue in chain:\n",
    "                # print(residue)\n",
    "                if residue.get_resname() in ['A', 'U', 'G', 'C']:\n",
    "                    # Check if the residue has a C1' atom\n",
    "                    if 'C1\\'' in residue:\n",
    "                        atom = residue['C1\\'']\n",
    "                        xyz = atom.get_coord()\n",
    "                        resname = residue.get_resname()\n",
    "                        resid = residue.get_id()[1]\n",
    "\n",
    "                        #todo detect discontinous: resid = prev_resid+1\n",
    "                        #ID\tresname\tresid\tx_1\ty_1\tz_1\n",
    "                        chain_data.append(dict(\n",
    "                            ID = target_id+'_'+str(resid),\n",
    "                            resname=resname,\n",
    "                            resid=resid,\n",
    "                            x_1=xyz[0],\n",
    "                            y_1=xyz[1],\n",
    "                            z_1=xyz[2],\n",
    "                        ))\n",
    "                        ##print(f\"Residue {resname} {resid}, Atom: {atom.get_name()}, xyz: {xyz}\")\n",
    "\n",
    "            if len(chain_data)!=0:\n",
    "                chain_df = pd.DataFrame(chain_data)\n",
    "                df.append(chain_df)\n",
    "                ##print(chain_df)\n",
    "    return df\n",
    "\n",
    "# usalign helper --------------------\n",
    "def write_target_line(\n",
    "    atom_name, atom_serial, residue_name, chain_id, residue_num, x_coord, y_coord, z_coord, occupancy=1.0, b_factor=0.0, atom_type='P'\n",
    "):\n",
    "    \"\"\"\n",
    "    Writes a single line of PDB format based on provided atom information.\n",
    "\n",
    "    Args:\n",
    "        atom_name (str): Name of the atom (e.g., \"N\", \"CA\").\n",
    "        atom_serial (int): Atom serial number.\n",
    "        residue_name (str): Residue name (e.g., \"ALA\").\n",
    "        chain_id (str): Chain identifier.\n",
    "        residue_num (int): Residue number.\n",
    "        x_coord (float): X coordinate.\n",
    "        y_coord (float): Y coordinate.\n",
    "        z_coord (float): Z coordinate.\n",
    "        occupancy (float, optional): Occupancy value (default: 1.0).\n",
    "        b_factor (float, optional): B-factor value (default: 0.0).\n",
    "\n",
    "    Returns:\n",
    "        str: A single line of PDB string.\n",
    "    \"\"\"\n",
    "    return f'ATOM  {atom_serial:>5d}  {atom_name:<5s} {residue_name:<3s} {residue_num:>3d}    {x_coord:>8.3f}{y_coord:>8.3f}{z_coord:>8.3f}{occupancy:>6.2f}{b_factor:>6.2f}           {atom_type}\\n'\n",
    "\n",
    "def write_xyz_to_pdb(df, pdb_file, xyz_id = 1):\n",
    "    resolved_cnt = 0\n",
    "    with open(pdb_file, 'w') as target_file:\n",
    "        for _, row in df.iterrows():\n",
    "            x_coord = row[f'x_{xyz_id}']\n",
    "            y_coord = row[f'y_{xyz_id}']\n",
    "            z_coord = row[f'z_{xyz_id}']\n",
    "\n",
    "            if x_coord > -1e17 and y_coord > -1e17 and z_coord > -1e17:\n",
    "                resolved_cnt += 1\n",
    "                target_line = write_target_line(\n",
    "                    atom_name=\"C1'\",\n",
    "                    atom_serial=int(row['resid']),\n",
    "                    residue_name=row['resname'],\n",
    "                    chain_id='0',\n",
    "                    residue_num=int(row['resid']),\n",
    "                    x_coord=x_coord,\n",
    "                    y_coord=y_coord,\n",
    "                    z_coord=z_coord,\n",
    "                    atom_type='C',\n",
    "                )\n",
    "                target_file.write(target_line)\n",
    "    return resolved_cnt\n",
    "\n",
    "def parse_usalign_for_tm_score(output):\n",
    "    # Extract TM-score based on length of reference structure (second)\n",
    "    tm_score_match = re.findall(r'TM-score=\\s+([\\d.]+)', output)[1]\n",
    "    if not tm_score_match:\n",
    "        raise ValueError('No TM score found')\n",
    "    return float(tm_score_match)\n",
    "\n",
    "def parse_usalign_for_transform(output):\n",
    "    # Locate the rotation matrix section\n",
    "    matrix_lines = []\n",
    "    found_matrix = False\n",
    "\n",
    "    for line in output.splitlines():\n",
    "        if \"The rotation matrix to rotate Structure_1 to Structure_2\" in line:\n",
    "            found_matrix = True\n",
    "        elif found_matrix and re.match(r'^\\d+\\s+[-\\d.]+\\s+[-\\d.]+\\s+[-\\d.]+\\s+[-\\d.]+$', line):\n",
    "            matrix_lines.append(line)\n",
    "        elif found_matrix and not line.strip():\n",
    "            break  # Stop parsing if an empty line is encountered after the matrix\n",
    "\n",
    "    # Parse the rotation matrix values\n",
    "    rotation_matrix = []\n",
    "    for line in matrix_lines:\n",
    "        parts = line.split()\n",
    "        row_values = list(map(float, parts[1:]))  # Skip the first column (index)\n",
    "        rotation_matrix.append(row_values)\n",
    "\n",
    "    return np.array(rotation_matrix)\n",
    "\n",
    "def call_usalign(predict_df, truth_df, verbose=1):\n",
    "    truth_pdb = '~truth.pdb'\n",
    "    predict_pdb = '~predict.pdb'\n",
    "    write_xyz_to_pdb(predict_df, predict_pdb, xyz_id=1)\n",
    "    write_xyz_to_pdb(truth_df, truth_pdb, xyz_id=1)\n",
    "\n",
    "    command = f'{USALIGN} {predict_pdb} {truth_pdb} -atom \" C1\\'\" -m -'\n",
    "    output = os.popen(command).read()\n",
    "    if verbose==1:\n",
    "        print(output)\n",
    "    tm_score = parse_usalign_for_tm_score(output)\n",
    "    transform = parse_usalign_for_transform(output)\n",
    "    return tm_score, transform\n",
    "\n",
    "print('HELPER OK!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d52edc9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T05:37:28.794741Z",
     "iopub.status.busy": "2025-05-13T05:37:28.794499Z",
     "iopub.status.idle": "2025-05-13T05:37:33.838075Z",
     "shell.execute_reply": "2025-05-13T05:37:33.837400Z"
    },
    "papermill": {
     "duration": 5.049774,
     "end_time": "2025-05-13T05:37:33.839668",
     "exception": false,
     "start_time": "2025-05-13T05:37:28.789894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_TYPE=='protenix':\n",
    "    \n",
    "    \n",
    "    from runner.batch_inference import get_default_runner\n",
    "    from runner.inference import update_inference_configs, InferenceRunner\n",
    "\n",
    "    from protenix.data.infer_data_pipeline import InferenceDataset\n",
    "\n",
    "    np.random.seed(0)\n",
    "    torch.random.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "    class DictDataset(InferenceDataset):\n",
    "        def __init__(\n",
    "            self,\n",
    "            seq_list: list,\n",
    "            dump_dir: str,\n",
    "            id_list: list = None,\n",
    "            use_msa: bool = False,\n",
    "        ) -> None:\n",
    "\n",
    "            self.dump_dir = dump_dir\n",
    "            self.use_msa = use_msa\n",
    "            if isinstance(id_list,type(None)):\n",
    "                self.inputs = [{\"sequences\": \n",
    "                                [{\"rnaSequence\": \n",
    "                                  {\"sequence\": seq, \n",
    "                                   \"count\": 1}}],\n",
    "                                \"name\": \"query\"} for seq in seq_list]\n",
    "            else:\n",
    "                self.inputs = [{\"sequences\": \n",
    "                                [{\"rnaSequence\": \n",
    "                                  {\"sequence\": seq, \n",
    "                                   \"count\": 1}}],\n",
    "                                \"name\": i} for i, seq in zip(id_list,seq_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a260ac90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T05:37:33.849337Z",
     "iopub.status.busy": "2025-05-13T05:37:33.848892Z",
     "iopub.status.idle": "2025-05-13T05:37:51.465029Z",
     "shell.execute_reply": "2025-05-13T05:37:51.464172Z"
    },
    "papermill": {
     "duration": 17.623407,
     "end_time": "2025-05-13T05:37:51.467507",
     "exception": false,
     "start_time": "2025-05-13T05:37:33.844100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scheduler 16.0\n",
      "inference scheduler 16.0\n",
      "Diffusion Module has 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/runner/inference.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'protenix.model.protenix.Protenix'>\n",
      "Protenix(\n",
      "  (input_embedder): InputFeatureEmbedder(\n",
      "    (atom_attention_encoder): AtomAttentionEncoder(\n",
      "      (linear_no_bias_f): Linear(in_features=389, out_features=128, bias=False)\n",
      "      (linear_no_bias_d): Linear(in_features=3, out_features=16, bias=False)\n",
      "      (linear_no_bias_invd): Linear(in_features=1, out_features=16, bias=False)\n",
      "      (linear_no_bias_v): Linear(in_features=1, out_features=16, bias=False)\n",
      "      (linear_no_bias_cl): Linear(in_features=128, out_features=16, bias=False)\n",
      "      (linear_no_bias_cm): Linear(in_features=128, out_features=16, bias=False)\n",
      "      (small_mlp): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): Linear(in_features=16, out_features=16, bias=False)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=16, out_features=16, bias=False)\n",
      "        (4): ReLU()\n",
      "        (5): Linear(in_features=16, out_features=16, bias=False)\n",
      "      )\n",
      "      (atom_transformer): AtomTransformer(\n",
      "        (diffusion_transformer): DiffusionTransformer(\n",
      "          (blocks): ModuleList(\n",
      "            (0-2): 3 x DiffusionTransformerBlock(\n",
      "              (attention_pair_bias): AttentionPairBias(\n",
      "                (layernorm_a): AdaptiveLayerNorm(\n",
      "                  (layernorm_a): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
      "                  (layernorm_s): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "                  (linear_s): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (linear_nobias_s): Linear(in_features=128, out_features=128, bias=False)\n",
      "                )\n",
      "                (linear_a_last): BiasInitLinear(in_features=128, out_features=128, bias=True)\n",
      "                (attention): Attention(\n",
      "                  (linear_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (linear_k): Linear(in_features=128, out_features=128, bias=False)\n",
      "                  (linear_v): Linear(in_features=128, out_features=128, bias=False)\n",
      "                  (linear_o): Linear(in_features=128, out_features=128, bias=False)\n",
      "                  (linear_g): Linear(in_features=128, out_features=128, bias=False)\n",
      "                  (sigmoid): Sigmoid()\n",
      "                )\n",
      "                (layernorm_z): OpenFoldLayerNorm()\n",
      "                (linear_nobias_z): Linear(in_features=16, out_features=4, bias=False)\n",
      "              )\n",
      "              (conditioned_transition_block): ConditionedTransitionBlock(\n",
      "                (adaln): AdaptiveLayerNorm(\n",
      "                  (layernorm_a): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
      "                  (layernorm_s): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "                  (linear_s): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (linear_nobias_s): Linear(in_features=128, out_features=128, bias=False)\n",
      "                )\n",
      "                (linear_nobias_a1): Linear(in_features=128, out_features=256, bias=False)\n",
      "                (linear_nobias_a2): Linear(in_features=128, out_features=256, bias=False)\n",
      "                (linear_nobias_b): Linear(in_features=256, out_features=128, bias=False)\n",
      "                (linear_s): BiasInitLinear(in_features=128, out_features=128, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (linear_no_bias_q): Linear(in_features=128, out_features=384, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (relative_position_encoding): RelativePositionEncoding(\n",
      "    (linear_no_bias): Linear(in_features=139, out_features=128, bias=False)\n",
      "  )\n",
      "  (template_embedder): TemplateEmbedder(\n",
      "    (linear_no_bias_z): Linear(in_features=128, out_features=64, bias=False)\n",
      "    (layernorm_z): OpenFoldLayerNorm()\n",
      "    (linear_no_bias_a): Linear(in_features=108, out_features=64, bias=False)\n",
      "    (pairformer_stack): PairformerStack(\n",
      "      (blocks): ModuleList()\n",
      "    )\n",
      "    (layernorm_v): OpenFoldLayerNorm()\n",
      "    (linear_no_bias_u): Linear(in_features=64, out_features=128, bias=False)\n",
      "  )\n",
      "  (msa_module): MSAModule(\n",
      "    (linear_no_bias_m): Linear(in_features=34, out_features=64, bias=False)\n",
      "    (linear_no_bias_s): Linear(in_features=449, out_features=64, bias=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0-2): 3 x MSABlock(\n",
      "        (outer_product_mean_msa): OuterProductMean(\n",
      "          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear_1): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (linear_2): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (linear_out): Linear(in_features=1024, out_features=128, bias=True)\n",
      "        )\n",
      "        (msa_stack): MSAStack(\n",
      "          (msa_pair_weighted_averaging): MSAPairWeightedAveraging(\n",
      "            (layernorm_m): OpenFoldLayerNorm()\n",
      "            (linear_no_bias_mv): Linear(in_features=64, out_features=64, bias=False)\n",
      "            (layernorm_z): OpenFoldLayerNorm()\n",
      "            (linear_no_bias_z): Linear(in_features=128, out_features=8, bias=False)\n",
      "            (linear_no_bias_mg): Linear(in_features=64, out_features=64, bias=False)\n",
      "            (softmax_w): Softmax(dim=-2)\n",
      "            (linear_no_bias_out): Linear(in_features=64, out_features=64, bias=False)\n",
      "          )\n",
      "          (dropout_row): DropoutRowwise(\n",
      "            (dropout): Dropout(p=0.15, inplace=False)\n",
      "          )\n",
      "          (transition_m): Transition(\n",
      "            (layernorm1): OpenFoldLayerNorm()\n",
      "            (linear_no_bias_a): Linear(in_features=64, out_features=256, bias=False)\n",
      "            (linear_no_bias_b): Linear(in_features=64, out_features=256, bias=False)\n",
      "            (linear_no_bias): Linear(in_features=256, out_features=64, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (pair_stack): PairformerBlock(\n",
      "          (tri_mul_out): TriangleMultiplicationOutgoing(\n",
      "            (linear_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_z): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (layer_norm_in): OpenFoldLayerNorm()\n",
      "            (layer_norm_out): OpenFoldLayerNorm()\n",
      "            (sigmoid): Sigmoid()\n",
      "            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (tri_mul_in): TriangleMultiplicationIncoming(\n",
      "            (linear_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_z): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (layer_norm_in): OpenFoldLayerNorm()\n",
      "            (layer_norm_out): OpenFoldLayerNorm()\n",
      "            (sigmoid): Sigmoid()\n",
      "            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (tri_att_start): TriangleAttention(\n",
      "            (layer_norm): OpenFoldLayerNorm()\n",
      "            (linear): Linear(in_features=128, out_features=4, bias=False)\n",
      "            (mha): Attention(\n",
      "              (linear_q): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_k): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_v): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (linear_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (sigmoid): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (tri_att_end): TriangleAttention(\n",
      "            (layer_norm): OpenFoldLayerNorm()\n",
      "            (linear): Linear(in_features=128, out_features=4, bias=False)\n",
      "            (mha): Attention(\n",
      "              (linear_q): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_k): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_v): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (linear_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (sigmoid): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (dropout_row): DropoutRowwise(\n",
      "            (dropout): Dropout(p=0.25, inplace=False)\n",
      "          )\n",
      "          (pair_transition): Transition(\n",
      "            (layernorm1): OpenFoldLayerNorm()\n",
      "            (linear_no_bias_a): Linear(in_features=128, out_features=512, bias=False)\n",
      "            (linear_no_bias_b): Linear(in_features=128, out_features=512, bias=False)\n",
      "            (linear_no_bias): Linear(in_features=512, out_features=128, bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): MSABlock(\n",
      "        (outer_product_mean_msa): OuterProductMean(\n",
      "          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (linear_1): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (linear_2): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (linear_out): Linear(in_features=1024, out_features=128, bias=True)\n",
      "        )\n",
      "        (pair_stack): PairformerBlock(\n",
      "          (tri_mul_out): TriangleMultiplicationOutgoing(\n",
      "            (linear_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_z): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (layer_norm_in): OpenFoldLayerNorm()\n",
      "            (layer_norm_out): OpenFoldLayerNorm()\n",
      "            (sigmoid): Sigmoid()\n",
      "            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (tri_mul_in): TriangleMultiplicationIncoming(\n",
      "            (linear_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_z): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (layer_norm_in): OpenFoldLayerNorm()\n",
      "            (layer_norm_out): OpenFoldLayerNorm()\n",
      "            (sigmoid): Sigmoid()\n",
      "            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (tri_att_start): TriangleAttention(\n",
      "            (layer_norm): OpenFoldLayerNorm()\n",
      "            (linear): Linear(in_features=128, out_features=4, bias=False)\n",
      "            (mha): Attention(\n",
      "              (linear_q): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_k): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_v): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (linear_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (sigmoid): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (tri_att_end): TriangleAttention(\n",
      "            (layer_norm): OpenFoldLayerNorm()\n",
      "            (linear): Linear(in_features=128, out_features=4, bias=False)\n",
      "            (mha): Attention(\n",
      "              (linear_q): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_k): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_v): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (linear_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (sigmoid): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (dropout_row): DropoutRowwise(\n",
      "            (dropout): Dropout(p=0.25, inplace=False)\n",
      "          )\n",
      "          (pair_transition): Transition(\n",
      "            (layernorm1): OpenFoldLayerNorm()\n",
      "            (linear_no_bias_a): Linear(in_features=128, out_features=512, bias=False)\n",
      "            (linear_no_bias_b): Linear(in_features=128, out_features=512, bias=False)\n",
      "            (linear_no_bias): Linear(in_features=512, out_features=128, bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pairformer_stack): PairformerStack(\n",
      "    (blocks): ModuleList(\n",
      "      (0-47): 48 x PairformerBlock(\n",
      "        (tri_mul_out): TriangleMultiplicationOutgoing(\n",
      "          (linear_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (linear_z): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (layer_norm_in): OpenFoldLayerNorm()\n",
      "          (layer_norm_out): OpenFoldLayerNorm()\n",
      "          (sigmoid): Sigmoid()\n",
      "          (linear_a_p): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (linear_a_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (linear_b_p): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (linear_b_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (tri_mul_in): TriangleMultiplicationIncoming(\n",
      "          (linear_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (linear_z): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (layer_norm_in): OpenFoldLayerNorm()\n",
      "          (layer_norm_out): OpenFoldLayerNorm()\n",
      "          (sigmoid): Sigmoid()\n",
      "          (linear_a_p): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (linear_a_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (linear_b_p): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (linear_b_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (tri_att_start): TriangleAttention(\n",
      "          (layer_norm): OpenFoldLayerNorm()\n",
      "          (linear): Linear(in_features=128, out_features=4, bias=False)\n",
      "          (mha): Attention(\n",
      "            (linear_q): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (linear_k): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (linear_v): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (linear_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (tri_att_end): TriangleAttention(\n",
      "          (layer_norm): OpenFoldLayerNorm()\n",
      "          (linear): Linear(in_features=128, out_features=4, bias=False)\n",
      "          (mha): Attention(\n",
      "            (linear_q): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (linear_k): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (linear_v): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (linear_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (dropout_row): DropoutRowwise(\n",
      "          (dropout): Dropout(p=0.25, inplace=False)\n",
      "        )\n",
      "        (pair_transition): Transition(\n",
      "          (layernorm1): OpenFoldLayerNorm()\n",
      "          (linear_no_bias_a): Linear(in_features=128, out_features=512, bias=False)\n",
      "          (linear_no_bias_b): Linear(in_features=128, out_features=512, bias=False)\n",
      "          (linear_no_bias): Linear(in_features=512, out_features=128, bias=False)\n",
      "        )\n",
      "        (attention_pair_bias): AttentionPairBias(\n",
      "          (layernorm_a): OpenFoldLayerNorm()\n",
      "          (attention): Attention(\n",
      "            (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (linear_k): Linear(in_features=384, out_features=384, bias=False)\n",
      "            (linear_v): Linear(in_features=384, out_features=384, bias=False)\n",
      "            (linear_o): Linear(in_features=384, out_features=384, bias=False)\n",
      "            (linear_g): Linear(in_features=384, out_features=384, bias=False)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "          (layernorm_z): OpenFoldLayerNorm()\n",
      "          (linear_nobias_z): Linear(in_features=128, out_features=16, bias=False)\n",
      "        )\n",
      "        (single_transition): Transition(\n",
      "          (layernorm1): OpenFoldLayerNorm()\n",
      "          (linear_no_bias_a): Linear(in_features=384, out_features=1536, bias=False)\n",
      "          (linear_no_bias_b): Linear(in_features=384, out_features=1536, bias=False)\n",
      "          (linear_no_bias): Linear(in_features=1536, out_features=384, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (diffusion_module): DiffusionModule(\n",
      "    (diffusion_conditioning): DiffusionConditioning(\n",
      "      (relpe): RelativePositionEncoding(\n",
      "        (linear_no_bias): Linear(in_features=139, out_features=128, bias=False)\n",
      "      )\n",
      "      (layernorm_z): OpenFoldLayerNorm()\n",
      "      (linear_no_bias_z): Linear(in_features=256, out_features=128, bias=False)\n",
      "      (transition_z1): Transition(\n",
      "        (layernorm1): OpenFoldLayerNorm()\n",
      "        (linear_no_bias_a): Linear(in_features=128, out_features=256, bias=False)\n",
      "        (linear_no_bias_b): Linear(in_features=128, out_features=256, bias=False)\n",
      "        (linear_no_bias): Linear(in_features=256, out_features=128, bias=False)\n",
      "      )\n",
      "      (transition_z2): Transition(\n",
      "        (layernorm1): OpenFoldLayerNorm()\n",
      "        (linear_no_bias_a): Linear(in_features=128, out_features=256, bias=False)\n",
      "        (linear_no_bias_b): Linear(in_features=128, out_features=256, bias=False)\n",
      "        (linear_no_bias): Linear(in_features=256, out_features=128, bias=False)\n",
      "      )\n",
      "      (layernorm_s): OpenFoldLayerNorm()\n",
      "      (linear_no_bias_s): Linear(in_features=833, out_features=384, bias=False)\n",
      "      (fourier_embedding): FourierEmbedding()\n",
      "      (layernorm_n): OpenFoldLayerNorm()\n",
      "      (linear_no_bias_n): Linear(in_features=256, out_features=384, bias=False)\n",
      "      (transition_s1): Transition(\n",
      "        (layernorm1): OpenFoldLayerNorm()\n",
      "        (linear_no_bias_a): Linear(in_features=384, out_features=768, bias=False)\n",
      "        (linear_no_bias_b): Linear(in_features=384, out_features=768, bias=False)\n",
      "        (linear_no_bias): Linear(in_features=768, out_features=384, bias=False)\n",
      "      )\n",
      "      (transition_s2): Transition(\n",
      "        (layernorm1): OpenFoldLayerNorm()\n",
      "        (linear_no_bias_a): Linear(in_features=384, out_features=768, bias=False)\n",
      "        (linear_no_bias_b): Linear(in_features=384, out_features=768, bias=False)\n",
      "        (linear_no_bias): Linear(in_features=768, out_features=384, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (atom_attention_encoder): AtomAttentionEncoder(\n",
      "      (linear_no_bias_f): Linear(in_features=389, out_features=128, bias=False)\n",
      "      (linear_no_bias_d): Linear(in_features=3, out_features=16, bias=False)\n",
      "      (linear_no_bias_invd): Linear(in_features=1, out_features=16, bias=False)\n",
      "      (linear_no_bias_v): Linear(in_features=1, out_features=16, bias=False)\n",
      "      (layernorm_s): OpenFoldLayerNorm()\n",
      "      (linear_no_bias_s): Linear(in_features=384, out_features=128, bias=False)\n",
      "      (layernorm_z): OpenFoldLayerNorm()\n",
      "      (linear_no_bias_z): Linear(in_features=128, out_features=16, bias=False)\n",
      "      (linear_no_bias_r): Linear(in_features=3, out_features=128, bias=False)\n",
      "      (linear_no_bias_cl): Linear(in_features=128, out_features=16, bias=False)\n",
      "      (linear_no_bias_cm): Linear(in_features=128, out_features=16, bias=False)\n",
      "      (small_mlp): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): Linear(in_features=16, out_features=16, bias=False)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=16, out_features=16, bias=False)\n",
      "        (4): ReLU()\n",
      "        (5): Linear(in_features=16, out_features=16, bias=False)\n",
      "      )\n",
      "      (atom_transformer): AtomTransformer(\n",
      "        (diffusion_transformer): DiffusionTransformer(\n",
      "          (blocks): ModuleList(\n",
      "            (0-2): 3 x DiffusionTransformerBlock(\n",
      "              (attention_pair_bias): AttentionPairBias(\n",
      "                (layernorm_a): AdaptiveLayerNorm(\n",
      "                  (layernorm_a): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
      "                  (layernorm_s): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "                  (linear_s): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (linear_nobias_s): Linear(in_features=128, out_features=128, bias=False)\n",
      "                )\n",
      "                (linear_a_last): BiasInitLinear(in_features=128, out_features=128, bias=True)\n",
      "                (attention): Attention(\n",
      "                  (linear_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (linear_k): Linear(in_features=128, out_features=128, bias=False)\n",
      "                  (linear_v): Linear(in_features=128, out_features=128, bias=False)\n",
      "                  (linear_o): Linear(in_features=128, out_features=128, bias=False)\n",
      "                  (linear_g): Linear(in_features=128, out_features=128, bias=False)\n",
      "                  (sigmoid): Sigmoid()\n",
      "                )\n",
      "                (layernorm_z): OpenFoldLayerNorm()\n",
      "                (linear_nobias_z): Linear(in_features=16, out_features=4, bias=False)\n",
      "              )\n",
      "              (conditioned_transition_block): ConditionedTransitionBlock(\n",
      "                (adaln): AdaptiveLayerNorm(\n",
      "                  (layernorm_a): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
      "                  (layernorm_s): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "                  (linear_s): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (linear_nobias_s): Linear(in_features=128, out_features=128, bias=False)\n",
      "                )\n",
      "                (linear_nobias_a1): Linear(in_features=128, out_features=256, bias=False)\n",
      "                (linear_nobias_a2): Linear(in_features=128, out_features=256, bias=False)\n",
      "                (linear_nobias_b): Linear(in_features=256, out_features=128, bias=False)\n",
      "                (linear_s): BiasInitLinear(in_features=128, out_features=128, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (linear_no_bias_q): Linear(in_features=128, out_features=768, bias=False)\n",
      "    )\n",
      "    (layernorm_s): OpenFoldLayerNorm()\n",
      "    (linear_no_bias_s): Linear(in_features=384, out_features=768, bias=False)\n",
      "    (diffusion_transformer): DiffusionTransformer(\n",
      "      (blocks): ModuleList(\n",
      "        (0-23): 24 x DiffusionTransformerBlock(\n",
      "          (attention_pair_bias): AttentionPairBias(\n",
      "            (layernorm_a): AdaptiveLayerNorm(\n",
      "              (layernorm_a): LayerNorm((768,), eps=1e-05, elementwise_affine=False)\n",
      "              (layernorm_s): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (linear_s): Linear(in_features=384, out_features=768, bias=True)\n",
      "              (linear_nobias_s): Linear(in_features=384, out_features=768, bias=False)\n",
      "            )\n",
      "            (linear_a_last): BiasInitLinear(in_features=384, out_features=768, bias=True)\n",
      "            (attention): Attention(\n",
      "              (linear_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (linear_k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (linear_v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (linear_o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (linear_g): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (sigmoid): Sigmoid()\n",
      "            )\n",
      "            (layernorm_z): OpenFoldLayerNorm()\n",
      "            (linear_nobias_z): Linear(in_features=128, out_features=16, bias=False)\n",
      "          )\n",
      "          (conditioned_transition_block): ConditionedTransitionBlock(\n",
      "            (adaln): AdaptiveLayerNorm(\n",
      "              (layernorm_a): LayerNorm((768,), eps=1e-05, elementwise_affine=False)\n",
      "              (layernorm_s): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (linear_s): Linear(in_features=384, out_features=768, bias=True)\n",
      "              (linear_nobias_s): Linear(in_features=384, out_features=768, bias=False)\n",
      "            )\n",
      "            (linear_nobias_a1): Linear(in_features=768, out_features=1536, bias=False)\n",
      "            (linear_nobias_a2): Linear(in_features=768, out_features=1536, bias=False)\n",
      "            (linear_nobias_b): Linear(in_features=1536, out_features=768, bias=False)\n",
      "            (linear_s): BiasInitLinear(in_features=384, out_features=768, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layernorm_a): OpenFoldLayerNorm()\n",
      "    (atom_attention_decoder): AtomAttentionDecoder(\n",
      "      (linear_no_bias_a): Linear(in_features=768, out_features=128, bias=False)\n",
      "      (layernorm_q): OpenFoldLayerNorm()\n",
      "      (linear_no_bias_out): Linear(in_features=128, out_features=3, bias=False)\n",
      "      (atom_transformer): AtomTransformer(\n",
      "        (diffusion_transformer): DiffusionTransformer(\n",
      "          (blocks): ModuleList(\n",
      "            (0-2): 3 x DiffusionTransformerBlock(\n",
      "              (attention_pair_bias): AttentionPairBias(\n",
      "                (layernorm_a): AdaptiveLayerNorm(\n",
      "                  (layernorm_a): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
      "                  (layernorm_s): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "                  (linear_s): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (linear_nobias_s): Linear(in_features=128, out_features=128, bias=False)\n",
      "                )\n",
      "                (linear_a_last): BiasInitLinear(in_features=128, out_features=128, bias=True)\n",
      "                (attention): Attention(\n",
      "                  (linear_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (linear_k): Linear(in_features=128, out_features=128, bias=False)\n",
      "                  (linear_v): Linear(in_features=128, out_features=128, bias=False)\n",
      "                  (linear_o): Linear(in_features=128, out_features=128, bias=False)\n",
      "                  (linear_g): Linear(in_features=128, out_features=128, bias=False)\n",
      "                  (sigmoid): Sigmoid()\n",
      "                )\n",
      "                (layernorm_z): OpenFoldLayerNorm()\n",
      "                (linear_nobias_z): Linear(in_features=16, out_features=4, bias=False)\n",
      "              )\n",
      "              (conditioned_transition_block): ConditionedTransitionBlock(\n",
      "                (adaln): AdaptiveLayerNorm(\n",
      "                  (layernorm_a): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
      "                  (layernorm_s): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "                  (linear_s): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (linear_nobias_s): Linear(in_features=128, out_features=128, bias=False)\n",
      "                )\n",
      "                (linear_nobias_a1): Linear(in_features=128, out_features=256, bias=False)\n",
      "                (linear_nobias_a2): Linear(in_features=128, out_features=256, bias=False)\n",
      "                (linear_nobias_b): Linear(in_features=256, out_features=128, bias=False)\n",
      "                (linear_s): BiasInitLinear(in_features=128, out_features=128, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (distogram_head): DistogramHead(\n",
      "    (linear): Linear(in_features=128, out_features=64, bias=True)\n",
      "  )\n",
      "  (confidence_head): ConfidenceHead(\n",
      "    (linear_no_bias_s1): Linear(in_features=449, out_features=128, bias=False)\n",
      "    (linear_no_bias_s2): Linear(in_features=449, out_features=128, bias=False)\n",
      "    (linear_no_bias_d): Linear(in_features=39, out_features=128, bias=False)\n",
      "    (pairformer_stack): PairformerStack(\n",
      "      (blocks): ModuleList(\n",
      "        (0-3): 4 x PairformerBlock(\n",
      "          (tri_mul_out): TriangleMultiplicationOutgoing(\n",
      "            (linear_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_z): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (layer_norm_in): OpenFoldLayerNorm()\n",
      "            (layer_norm_out): OpenFoldLayerNorm()\n",
      "            (sigmoid): Sigmoid()\n",
      "            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (tri_mul_in): TriangleMultiplicationIncoming(\n",
      "            (linear_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_z): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (layer_norm_in): OpenFoldLayerNorm()\n",
      "            (layer_norm_out): OpenFoldLayerNorm()\n",
      "            (sigmoid): Sigmoid()\n",
      "            (linear_a_p): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_a_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_b_p): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (linear_b_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (tri_att_start): TriangleAttention(\n",
      "            (layer_norm): OpenFoldLayerNorm()\n",
      "            (linear): Linear(in_features=128, out_features=4, bias=False)\n",
      "            (mha): Attention(\n",
      "              (linear_q): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_k): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_v): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (linear_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (sigmoid): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (tri_att_end): TriangleAttention(\n",
      "            (layer_norm): OpenFoldLayerNorm()\n",
      "            (linear): Linear(in_features=128, out_features=4, bias=False)\n",
      "            (mha): Attention(\n",
      "              (linear_q): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_k): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_v): Linear(in_features=128, out_features=128, bias=False)\n",
      "              (linear_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (linear_g): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (sigmoid): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (dropout_row): DropoutRowwise(\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (pair_transition): Transition(\n",
      "            (layernorm1): OpenFoldLayerNorm()\n",
      "            (linear_no_bias_a): Linear(in_features=128, out_features=512, bias=False)\n",
      "            (linear_no_bias_b): Linear(in_features=128, out_features=512, bias=False)\n",
      "            (linear_no_bias): Linear(in_features=512, out_features=128, bias=False)\n",
      "          )\n",
      "          (attention_pair_bias): AttentionPairBias(\n",
      "            (layernorm_a): OpenFoldLayerNorm()\n",
      "            (attention): Attention(\n",
      "              (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (linear_k): Linear(in_features=384, out_features=384, bias=False)\n",
      "              (linear_v): Linear(in_features=384, out_features=384, bias=False)\n",
      "              (linear_o): Linear(in_features=384, out_features=384, bias=False)\n",
      "              (linear_g): Linear(in_features=384, out_features=384, bias=False)\n",
      "              (sigmoid): Sigmoid()\n",
      "            )\n",
      "            (layernorm_z): OpenFoldLayerNorm()\n",
      "            (linear_nobias_z): Linear(in_features=128, out_features=16, bias=False)\n",
      "          )\n",
      "          (single_transition): Transition(\n",
      "            (layernorm1): OpenFoldLayerNorm()\n",
      "            (linear_no_bias_a): Linear(in_features=384, out_features=1536, bias=False)\n",
      "            (linear_no_bias_b): Linear(in_features=384, out_features=1536, bias=False)\n",
      "            (linear_no_bias): Linear(in_features=1536, out_features=384, bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (linear_no_bias_pae): Linear(in_features=128, out_features=64, bias=False)\n",
      "    (linear_no_bias_pde): Linear(in_features=128, out_features=64, bias=False)\n",
      "    (linear_no_bias_s_inputs): Linear(in_features=449, out_features=384, bias=False)\n",
      "    (linear_no_bias_s_trunk): Linear(in_features=384, out_features=384, bias=False)\n",
      "    (layernorm_s_trunk): OpenFoldLayerNorm()\n",
      "    (linear_no_bias_z_trunk): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (layernorm_z_trunk): OpenFoldLayerNorm()\n",
      "    (layernorm_no_bias_z_cat): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (layernorm_no_bias_s_cat): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (linear_no_bias_z_cat): Linear(in_features=256, out_features=128, bias=False)\n",
      "    (linear_no_bias_s_cat): Linear(in_features=768, out_features=384, bias=False)\n",
      "    (pae_ln): OpenFoldLayerNorm()\n",
      "    (pde_ln): OpenFoldLayerNorm()\n",
      "    (plddt_ln): OpenFoldLayerNorm()\n",
      "    (resolved_ln): OpenFoldLayerNorm()\n",
      "  )\n",
      "  (linear_no_bias_sinit): Linear(in_features=449, out_features=384, bias=False)\n",
      "  (linear_no_bias_zinit1): Linear(in_features=384, out_features=128, bias=False)\n",
      "  (linear_no_bias_zinit2): Linear(in_features=384, out_features=128, bias=False)\n",
      "  (linear_no_bias_token_bond): Linear(in_features=1, out_features=128, bias=False)\n",
      "  (linear_no_bias_z_cycle): Linear(in_features=128, out_features=128, bias=False)\n",
      "  (linear_no_bias_s): Linear(in_features=384, out_features=384, bias=False)\n",
      "  (layernorm_z_cycle): OpenFoldLayerNorm()\n",
      "  (layernorm_s): OpenFoldLayerNorm()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if MODEL_TYPE=='protenix':\n",
    "\n",
    "    from configs.configs_base import configs as configs_base\n",
    "    from configs.configs_data import data_configs\n",
    "    from configs.configs_inference import inference_configs\n",
    "    from protenix.config.config import parse_configs\n",
    "\n",
    "    configs_base[\"use_deepspeed_evo_attention\"] = (\n",
    "    os.environ.get(\"USE_DEEPSPEED_EVO_ATTENTION\", False) == \"true\")\n",
    "    configs_base[\"model\"][\"N_cycle\"] = 10 #10\n",
    "    configs_base[\"sample_diffusion\"][\"N_sample\"] = (1 if VALIDATION else 5)\n",
    "    configs_base[\"sample_diffusion\"][\"N_step\"] = 200\n",
    "    inference_configs['load_checkpoint_path']='/kaggle/input/protenix-checkpoints/model_v0.2.0.pt'\n",
    "    configs = {**configs_base, **{\"data\": data_configs}, **inference_configs}\n",
    "\n",
    "    configs = parse_configs(\n",
    "            configs=configs,\n",
    "            fill_required_with_null=True,\n",
    "        )\n",
    "    \n",
    "    runner=InferenceRunner(configs)\n",
    "    print(type(runner.model))          # 클래스 이름\n",
    "    print(runner.model)                # 전체 구조 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92dd0cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T05:37:51.479383Z",
     "iopub.status.busy": "2025-05-13T05:37:51.479119Z",
     "iopub.status.idle": "2025-05-13T05:37:51.819618Z",
     "shell.execute_reply": "2025-05-13T05:37:51.818728Z"
    },
    "papermill": {
     "duration": 0.347555,
     "end_time": "2025-05-13T05:37:51.821301",
     "exception": false,
     "start_time": "2025-05-13T05:37:51.473746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if VALIDATION:\n",
    "    LABEL_DF = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_labels.csv')\n",
    "    LABEL_DF['target_id'] = LABEL_DF['ID'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "    train_df=pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_sequences.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f4a7172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T05:37:51.833079Z",
     "iopub.status.busy": "2025-05-13T05:37:51.832799Z",
     "iopub.status.idle": "2025-05-13T08:56:35.168853Z",
     "shell.execute_reply": "2025-05-13T08:56:35.167936Z"
    },
    "papermill": {
     "duration": 11923.34322,
     "end_time": "2025-05-13T08:56:35.170169",
     "exception": false,
     "start_time": "2025-05-13T05:37:51.826949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 844/844 [3:18:42<00:00, 14.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34974713513513567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if MODEL_TYPE=='protenix' and VALIDATION:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")  \n",
    "    \n",
    "    train_df['protenix_tm_score']=None\n",
    "    dataset = DictDataset(train_df.sequence, dump_dir='output', id_list=train_df.target_id, use_msa=False)\n",
    "    num_data = len(dataset)\n",
    "    for i, seq in tqdm(enumerate(train_df.sequence),total=num_data):\n",
    "        if train_df.loc[i,'protenix_tm_score']!=None:\n",
    "            continue\n",
    "        if len(seq)>300:\n",
    "            continue\n",
    "        target_id = train_df.loc[i,'target_id']\n",
    "        truth_df = get_truth_df(target_id)\n",
    "        if sum(~np.isnan(truth_df.x_1))<3:\n",
    "            continue\n",
    "        data, atom_array, data_error_message=dataset[i]\n",
    "        if data_error_message!='':\n",
    "            continue\n",
    "        new_configs = update_inference_configs(configs, data[\"N_token\"].item())\n",
    "        runner.update_model_configs(new_configs)\n",
    "        prediction = runner.predict(data)\n",
    "        prediction=prediction['coordinate'][:,data['input_feature_dict']['atom_to_tokatom_idx']==12]       \n",
    "        result = parse_output_to_df(prediction[:1], seq, target_id)[0]\n",
    "        try:\n",
    "            tm_score, transform = call_usalign(result, truth_df, verbose=0)\n",
    "            train_df.loc[i,'protenix_tm_score']=tm_score\n",
    "        except:\n",
    "            pass\n",
    "        if (time.time()-time0)>(12*3600-360):\n",
    "            break\n",
    "    train_df.to_csv('tm_scores.csv', index=False)\n",
    "    print(train_df.protenix_tm_score.mean())\n",
    "    display(train_df.protenix_tm_score.hist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "370f9990",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T08:56:35.247944Z",
     "iopub.status.busy": "2025-05-13T08:56:35.247605Z",
     "iopub.status.idle": "2025-05-13T08:56:35.252458Z",
     "shell.execute_reply": "2025-05-13T08:56:35.251782Z"
    },
    "papermill": {
     "duration": 0.043688,
     "end_time": "2025-05-13T08:56:35.253827",
     "exception": false,
     "start_time": "2025-05-13T08:56:35.210139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def smooth_coords(df, sigma=1.0):\n",
    "    df = df.copy()\n",
    "    for n in range(1, 6):  # 5개의 구조 (x_1 ~ x_5, y_1 ~ y_5, z_1 ~ z_5)\n",
    "        for axis in ['x', 'y', 'z']:\n",
    "            col = f\"{axis}_{n}\"\n",
    "            if col in df.columns:\n",
    "                df[col] = gaussian_filter1d(df[col].values, sigma=sigma)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1176c5e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T08:56:35.328483Z",
     "iopub.status.busy": "2025-05-13T08:56:35.328200Z",
     "iopub.status.idle": "2025-05-13T08:56:35.335468Z",
     "shell.execute_reply": "2025-05-13T08:56:35.334826Z"
    },
    "papermill": {
     "duration": 0.046033,
     "end_time": "2025-05-13T08:56:35.336670",
     "exception": false,
     "start_time": "2025-05-13T08:56:35.290637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_TYPE=='protenix' and not VALIDATION:\n",
    "    test_df=pd.read_csv('/kaggle/input/stanford-rna-3d-folding/test_sequences.csv')\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")  \n",
    "    \n",
    "    dataset = DictDataset(test_df.sequence, dump_dir='output', id_list=test_df.target_id, use_msa_server=True)\n",
    "    num_data = len(dataset)\n",
    "    for i, seq in tqdm(enumerate(test_df.sequence),total=num_data):\n",
    "        try:\n",
    "            data, atom_array, data_error_message=dataset[i]\n",
    "            target_id = data[\"sample_name\"]\n",
    "            assert target_id==test_df.target_id[i]\n",
    "            assert data_error_message==''\n",
    "            \n",
    "            new_configs = update_inference_configs(configs, data[\"N_token\"].item())\n",
    "            runner.update_model_configs(new_configs)\n",
    "            prediction = runner.predict(data)\n",
    "            prediction=prediction['coordinate'][:,data['input_feature_dict']['atom_to_tokatom_idx']==12]\n",
    "\n",
    "            result = parse_output_to_df(prediction, seq, target_id)[0]\n",
    "        except:\n",
    "            target_id==test_df.target_id[i]\n",
    "            print('Failed to predict', target_id)\n",
    "            result=pd.DataFrame(columns=['ID', 'resname', 'resid', \n",
    "                                         'x_1', 'y_1', 'z_1', \n",
    "                                         'x_2', 'y_2', 'z_2',\n",
    "                                         'x_3', 'y_3', 'z_3', \n",
    "                                         'x_4', 'y_4', 'z_4', \n",
    "                                         'x_5', 'y_5', 'z_5'], \n",
    "                                         data=[[target_id, x, j+1] + [0.0]*15 for j, x in enumerate(seq)])\n",
    "        result = smooth_coords(result, sigma=1.0)\n",
    "        result['ID']=result.apply(lambda x: x.ID + '_' + str(x.resid), axis=1)\n",
    "        result.to_csv('submission.csv', index=False, mode='a', header=(i==0))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    display(pd.read_csv('submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01408122",
   "metadata": {
    "papermill": {
     "duration": 0.036238,
     "end_time": "2025-05-13T08:56:35.409380",
     "exception": false,
     "start_time": "2025-05-13T08:56:35.373142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1228611",
   "metadata": {
    "papermill": {
     "duration": 0.036425,
     "end_time": "2025-05-13T08:56:35.481966",
     "exception": false,
     "start_time": "2025-05-13T08:56:35.445541",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b5576f",
   "metadata": {
    "papermill": {
     "duration": 0.036349,
     "end_time": "2025-05-13T08:56:35.555385",
     "exception": false,
     "start_time": "2025-05-13T08:56:35.519036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12276181,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 6742586,
     "sourceId": 10855324,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6933267,
     "sourceId": 11118830,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 224830487,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 232367977,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11975.447522,
   "end_time": "2025-05-13T08:56:39.192801",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-13T05:37:03.745279",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
